{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802f2e05-64ef-4fac-a881-2d32753bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243bef72-56cb-4975-8139-7f23c119dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nbme-score-clinical-patient-notes/patient_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0b4156-3463-46c5-9542-6eccf880a432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"17-year-old male, has come to the student health clinic complaining of heart pounding. Mr. Cleveland's mother has given verbal consent for a history, physical examination, and treatment\\r\\n-began 2-3 months ago,sudden,intermittent for 2 days(lasting 3-4 min),worsening,non-allev/aggrav\\r\\n-associated with dispnea on exersion and rest,stressed out about school\\r\\n-reports fe feels like his heart is jumping out of his chest\\r\\n-ros:denies chest pain,dyaphoresis,wt loss,chills,fever,nausea,vomiting,pedal edeam\\r\\n-pmh:non,meds :aderol (from a friend),nkda\\r\\n-fh:father had MI recently,mother has thyroid dz\\r\\n-sh:non-smoker,mariguana 5-6 months ago,3 beers on the weekend, basketball at school\\r\\n-sh:no std\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pn_history'].head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760b8f24-c17e-4284-9739-2df8f41f31ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['pn_history'].head()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e61f8e-cff9-4249-8503-d4961b7f90f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        17-year-old male, has come to the student heal...\n",
       "1        17 yo male with recurrent palpitations for the...\n",
       "2        Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3        a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4        17yo male with no pmh here for evaluation of p...\n",
       "                               ...                        \n",
       "42141    Ms. Madden is a 20 yo female presenting w/ the...\n",
       "42142    A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "42143    Ms. Madden is a 20yo female who presents with ...\n",
       "42144    Stephanie madden is a 20 year old woman compla...\n",
       "42145    patient is a 20 yo F who presents with a heada...\n",
       "Name: pn_history, Length: 42146, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pn_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74c854f-05fc-4e70-9d37-717a1fa715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025ed290-f87f-4f6d-9ebb-72d078a52033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1bb79c99234e27b75c30066dd0a45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee626e7f008343a489f54dd20e28adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a621ab77b8a40f6848f1a9b5fb8609b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfa2eaf7d554cf48cbd04976b9fe2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762bf70298884313afaf176ef1430cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f14f31270346b1b908027aa43a255b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/804 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa18d8de5be401e80823873b1265858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658536fdc6a14f8b8b648b9bf90b1774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3118e8a1383e48a59aa38fbf5950e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2f89d80de24714a02f6635fb7015b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7876e8b8db7b4998af0d1461f7550b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c540fb8c7bc4dada201cc67f4aa5b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ec86da3b634c9f826d8aeff9a8b037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39418525dfd14fffbc30b0feec164d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 768, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "  (3): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_id = \"multi-qa-mpnet-base-dot-v1\"\n",
    "# model_id = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "model_id = \"LaBSE\"\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca52cbf-07f4-4858-af1e-07855ba4831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"I'm searching for a planet not too far from Earth.\" and \"Neptune is the eight...\" is: 0.483\n",
      "Cosine similarity between \"I'm searching for a planet not too far from Earth.\" and \"TRAPPIST-1d, also de...\" is: 0.453\n",
      "Cosine similarity between \"I'm searching for a planet not too far from Earth.\" and \"A harsh desert world...\" is: 0.305\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Muennighoff/sgpt#asymmetric-semantic-search-be\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Get our models - The package will take care of downloading the models automatically\n",
    "# For best performance: Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit\")\n",
    "model = AutoModel.from_pretrained(\"Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit\")\n",
    "# Deactivate Dropout (There is no dropout in the above models so it makes no difference here but other SGPT models may have dropout)\n",
    "model\n",
    "model.eval()\n",
    "\n",
    "queries = [\n",
    "    \"I'm searching for a planet not too far from Earth.\",\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    \"Neptune is the eighth and farthest-known Solar planet from the Sun. In the Solar System, it is the fourth-largest planet by diameter, the third-most-massive planet, and the densest giant planet. It is 17 times the mass of Earth, slightly more massive than its near-twin Uranus.\",\n",
    "    \"TRAPPIST-1d, also designated as 2MASS J23062928-0502285 d, is a small exoplanet (about 30% the mass of the earth), which orbits on the inner edge of the habitable zone of the ultracool dwarf star TRAPPIST-1 approximately 40 light-years (12.1 parsecs, or nearly 3.7336×1014 km) away from Earth in the constellation of Aquarius.\",\n",
    "    \"A harsh desert world orbiting twin suns in the galaxy’s Outer Rim, Tatooine is a lawless place ruled by Hutt gangsters. Many settlers scratch out a living on moisture farms, while spaceport cities such as Mos Eisley and Mos Espa serve as home base for smugglers, criminals, and other rogues.\",\n",
    "]\n",
    "\n",
    "SPECB_QUE_BOS = tokenizer.encode(\"[\", add_special_tokens=False)[0]\n",
    "SPECB_QUE_EOS = tokenizer.encode(\"]\", add_special_tokens=False)[0]\n",
    "\n",
    "SPECB_DOC_BOS = tokenizer.encode(\"{\", add_special_tokens=False)[0]\n",
    "SPECB_DOC_EOS = tokenizer.encode(\"}\", add_special_tokens=False)[0]\n",
    "\n",
    "\n",
    "def tokenize_with_specb(texts, is_query):\n",
    "    # Tokenize without padding\n",
    "    batch_tokens = tokenizer(texts, padding=False, truncation=True)   \n",
    "    # Add special brackets & pay attention to them\n",
    "    for seq, att in zip(batch_tokens[\"input_ids\"], batch_tokens[\"attention_mask\"]):\n",
    "        if is_query:\n",
    "            seq.insert(0, SPECB_QUE_BOS)\n",
    "            seq.append(SPECB_QUE_EOS)\n",
    "        else:\n",
    "            seq.insert(0, SPECB_DOC_BOS)\n",
    "            seq.append(SPECB_DOC_EOS)\n",
    "        att.insert(0, 1)\n",
    "        att.append(1)\n",
    "    # Add padding\n",
    "    batch_tokens = tokenizer.pad(batch_tokens, padding=True, return_tensors=\"pt\")\n",
    "    return batch_tokens\n",
    "\n",
    "def get_weightedmean_embedding(batch_tokens, model):\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        # Get hidden state of shape [bs, seq_len, hid_dim]\n",
    "        last_hidden_state = model(**batch_tokens, output_hidden_states=True, return_dict=True).last_hidden_state\n",
    "\n",
    "    # Get weights of shape [bs, seq_len, hid_dim]\n",
    "    weights = (\n",
    "        torch.arange(start=1, end=last_hidden_state.shape[1] + 1)\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float().to(last_hidden_state.device)\n",
    "    )\n",
    "\n",
    "    # Get attn mask of shape [bs, seq_len, hid_dim]\n",
    "    input_mask_expanded = (\n",
    "        batch_tokens[\"attention_mask\"]\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "    # Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
    "    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded * weights, dim=1)\n",
    "    sum_mask = torch.sum(input_mask_expanded * weights, dim=1)\n",
    "\n",
    "    embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "query_embeddings = get_weightedmean_embedding(tokenize_with_specb(queries, is_query=True), model)\n",
    "doc_embeddings = get_weightedmean_embedding(tokenize_with_specb(docs, is_query=False), model)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(query_embeddings[0], doc_embeddings[0])\n",
    "cosine_sim_0_2 = 1 - cosine(query_embeddings[0], doc_embeddings[1])\n",
    "cosine_sim_0_3 = 1 - cosine(query_embeddings[0], doc_embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[0][:20] + \"...\", cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[1][:20] + \"...\", cosine_sim_0_2))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[2][:20] + \"...\", cosine_sim_0_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5818b5c8-77d3-4cef-ba38-54eb4fbbc2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJModel(\n",
       "  (wte): Embedding(50402, 4096)\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): GPTJBlock(\n",
       "      (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPTJAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): GPTJMLP(\n",
       "        (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e64d1f-85e8-4c37-a1a0-1c3a5dc71db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'pooling_mode_weightedmean_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m             sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sentences \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentences, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sent \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences]    \n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mencode(sentences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerSpecb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMuennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model\n\u001b[1;32m     26\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(queries, is_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[1;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[1;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[1;32m    839\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 840\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[0;32m~/anaconda3/envs/clip/lib/python3.9/site-packages/sentence_transformers/models/Pooling.py:120\u001b[0m, in \u001b[0;36mPooling.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[1;32m    118\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPooling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'pooling_mode_weightedmean_tokens'"
     ]
    }
   ],
   "source": [
    "# https://github.com/Muennighoff/sgpt#asymmetric-semantic-search-be\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "queries = [\n",
    "    \"I'm searching for a planet not too far from Earth.\",\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    \"Neptune is the eighth and farthest-known Solar planet from the Sun. In the Solar System, it is the fourth-largest planet by diameter, the third-most-massive planet, and the densest giant planet. It is 17 times the mass of Earth, slightly more massive than its near-twin Uranus.\",\n",
    "    \"TRAPPIST-1d, also designated as 2MASS J23062928-0502285 d, is a small exoplanet (about 30% the mass of the earth), which orbits on the inner edge of the habitable zone of the ultracool dwarf star TRAPPIST-1 approximately 40 light-years (12.1 parsecs, or nearly 3.7336×1014 km) away from Earth in the constellation of Aquarius.\",\n",
    "    \"A harsh desert world orbiting twin suns in the galaxy’s Outer Rim, Tatooine is a lawless place ruled by Hutt gangsters. Many settlers scratch out a living on moisture farms, while spaceport cities such as Mos Eisley and Mos Espa serve as home base for smugglers, criminals, and other rogues.\",\n",
    "]\n",
    "\n",
    "class SentenceTransformerSpecb(SentenceTransformer):\n",
    "    def encode(self, sentences, **kwargs):\n",
    "        is_query = kwargs.pop(\"is_query\", True)\n",
    "        if is_query:\n",
    "            sentences = \"[\" + sentences + \"]\" if isinstance(sentences, str) else [\"[\" + sent + \"]\" for sent in sentences]\n",
    "        else:\n",
    "            sentences = \"{\" + sentences + \"}\" if isinstance(sentences, str) else [\"{\" + sent + \"}\" for sent in sentences]    \n",
    "        return super().encode(sentences, **kwargs)\n",
    "        \n",
    "model = SentenceTransformerSpecb(\"Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit\")\n",
    "model\n",
    "query_embeddings = model.encode(queries, is_query=True)\n",
    "doc_embeddings = model.encode(docs, is_query=False)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(query_embeddings[0], doc_embeddings[0])\n",
    "cosine_sim_0_2 = 1 - cosine(query_embeddings[0], doc_embeddings[1])\n",
    "cosine_sim_0_3 = 1 - cosine(query_embeddings[0], doc_embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[0][:20] + \"...\", cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[1][:20] + \"...\", cosine_sim_0_2))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (queries[0], docs[2][:20] + \"...\", cosine_sim_0_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41cb95-e46b-44aa-ad50-0adf7507238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a79ca4f-6725-454f-82b5-f1c51d10da7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\"\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d31e252-7621-4b20-af9e-0f1266a8b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/hwasiti/.cache/torch/sentence_transformers/microsoft_Multilingual-MiniLM-L12-H384. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a07939d-2df4-44da-ae8b-5acd9170433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6379b687f38d41179367759e33ec0a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ecd9158a064b2e90a2539e01f51dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e50062deac4d5a8bd1940355b8a94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/891 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf3fd3775e34075b732ef73bb177049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9519868fdc34c1d93dcc3293b04dc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0644d37446b24942bf4545d293aa0754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4331c28b15824e48b18f3e50e288376c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c097a81e2a43483e8557d2daf391ce04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9c3c8f7a5a4228bd54f4e36eab7d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/hwasiti/.cache/torch/sentence_transformers/cross-encoder_mmarco-mMiniLMv2-L12-H384-v1. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/hwasiti/.cache/torch/sentence_transformers/cross-encoder_mmarco-mMiniLMv2-L12-H384-v1 were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at /home/hwasiti/.cache/torch/sentence_transformers/cross-encoder_mmarco-mMiniLMv2-L12-H384-v1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\"\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1931a-626e-4714-977a-e282f9593982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
